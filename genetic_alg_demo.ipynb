{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c88f599-64cd-440d-b0ae-55ffac6d7257",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Genetic Algorithm\n",
    "\n",
    "Let's try to solve a standard numerical optimization \n",
    "$$\\max_{x}f(x) \\\\ \\text{subject to } x\\in [0,1]^2.$$\n",
    "\n",
    "### Population\n",
    "\n",
    "Our population is a collection of $n$ points in $[0,1]^2$. We will initialize by drawing $n$ points from a uniform distribution over the square.\n",
    "\n",
    "### Fitness\n",
    "\n",
    "We will measure fitness by evaluation of $f$.\n",
    "\n",
    "### Selection\n",
    "\n",
    "We will select the half of our population with the highest fitness. \n",
    "\n",
    "### Crossover/Reproduction\n",
    "\n",
    "We will crossover two individuals by (1) randomly selecting the $x$- or $y$-axis, (2) computing the mean of that coordinate between the two individuals, and (3) moving both individuals to the mean of that coordinate.\n",
    "\n",
    "### Mutation\n",
    "\n",
    "We will mutate each offspring by drawing a Bernoulli($p$) random variable. If we draw a $1$, we will add a multivariate normal perturbation to the point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68c8bfa-84f4-40c1-a257-84d873c6ca2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker, colors\n",
    "import time\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de68f612-12d7-4a91-bb07-0f88f2ebf47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Individual is a point in [0,1] x [0,1].\"\n",
    "class Individual(object):\n",
    "    x: float\n",
    "    y: float\n",
    "    \n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        return\n",
    "        \n",
    "    \"Creates an individual with random x and y coordinates.\"\n",
    "    @classmethod\n",
    "    def random(cls):\n",
    "        return cls(rng.random(), rng.random())\n",
    "    \n",
    "    \"\"\"\n",
    "    Mutates by adding Gaussian(0,0.1) noise with probability 1/2 and otherwise\n",
    "    doing nothing.\n",
    "    \"\"\"\n",
    "    def mutate(self):\n",
    "        if rng.random() > 0.4:\n",
    "            self.x = min(max(self.x + np.sqrt(0.05) * rng.normal(), 0), 1)\n",
    "            self.y = min(max(self.y + np.sqrt(0.05) * rng.normal(), 0), 1)\n",
    "        return\n",
    "       \n",
    "    def __str__(self):\n",
    "        return f\"Individual with coordinates ({float(self.x):1.4},{float(self.y):1.4})\"\n",
    "       \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if not isinstance(other, Individual):\n",
    "            return False\n",
    "        return self.x == other.x and self.y == other.y\n",
    "\n",
    "\"\"\"\n",
    "Turns two Individuals into two new individuals by replacing either both their x-coordinates \n",
    "with the average x-coordinate or both y-coordinates, each with probability 1/2\n",
    "\"\"\"\n",
    "def cross(parent_1, parent_2):\n",
    "        if rng.random() > 0.5:\n",
    "            mean_x = (parent_1.x + parent_2.x) / 2\n",
    "            child_1 = Individual(mean_x, parent_1.y)\n",
    "            child_2 = Individual(mean_x, parent_2.y)\n",
    "        else:\n",
    "            mean_y = (parent_1.y + parent_2.y) / 2\n",
    "            child_1 = Individual(parent_1.x, mean_y)\n",
    "            child_2 = Individual(parent_2.x, mean_y)\n",
    "        return child_1, child_2\n",
    "\n",
    "    \n",
    "\"Creates n random individuals\"\n",
    "def spawn(individual_class, n):\n",
    "    return [individual_class.random() for _ in range(n)]\n",
    "\n",
    "\n",
    "\"Finds all the individuals of the population who have at least median fitness\"\n",
    "def selection(objective, population):\n",
    "    fitnesses = [objective(individual) for individual in population]\n",
    "    median = np.median(fitnesses)\n",
    "    survivors = [individual for (individual, fitness) in zip(population, fitnesses) if fitness >= median]\n",
    "    return survivors\n",
    "\n",
    "\"Creates children by randomly pairing all parents\"\n",
    "def reproduction(cross, parents):\n",
    "    rng.shuffle(parents)\n",
    "    if len(parents) % 2 == 1:\n",
    "        parents.pop()\n",
    "    children = [child for mates in zip(parents[::2], parents[1::2]) for child in cross(*mates)]\n",
    "    for child in children:\n",
    "        child.mutate()\n",
    "    return children\n",
    "    \n",
    "\"\"\"\n",
    "Creates the next generation of a population by performing selection on the current \n",
    "generation, creating new children from the survivors, and then either randomly\n",
    "removing or randomly spawning new individuals to maintain the population size\n",
    "\"\"\"\n",
    "def evolve(population, size, spawner, selecter, reproducer):\n",
    "    parents = selecter(population)\n",
    "    children = reproducer(parents)\n",
    "    new_population = children + parents\n",
    "    new_size = len(new_population)\n",
    "    \n",
    "    if new_size > size:\n",
    "        rng.shuffle(new_population)\n",
    "        new_population = new_population[:size]\n",
    "    elif new_size < size:\n",
    "        new_population += spawner(size-new_size)\n",
    "    \n",
    "    return new_population\n",
    "\n",
    "\"\"\"\n",
    "Runs genetic algorithm given a class for creating individuals, an objective function,\n",
    "a crossover function, a population size, and a number of generations.\n",
    "\"\"\"\n",
    "def genetic_algorithm(individual_class, objective, cross, size, n_generations):\n",
    "    def spawner(n): return spawn(individual_class, n)\n",
    "    def selecter(pop): return selection(objective, pop)\n",
    "    def reproducer(parents): return reproduction(cross, parents)\n",
    "    def evolver(pop): return evolve(pop, size, spawner, selecter, reproducer)\n",
    "    \n",
    "    population = spawner(size)\n",
    "    yield population\n",
    "    for gen in range(n_generations):\n",
    "        population = evolver(population)\n",
    "        yield population\n",
    "    return\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5728265-6218-4403-ae58-2e55cafd68df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output\n",
    "\n",
    "def pop_to_coords(pop):\n",
    "    coords = [(ind.x, ind.y) for ind in pop]\n",
    "    return list(zip(*coords))\n",
    "\n",
    "def background_plot(f, logscale=False):\n",
    "    fig, ax = plt.subplots(dpi=400, figsize=(4,3))\n",
    "    X, Y = np.meshgrid(np.linspace(0,1,200),np.linspace(0,1,200))\n",
    "    Z = f(X,Y)\n",
    "    if logscale:\n",
    "        cs = ax.contourf(X,Y,-Z,locator=ticker.LogLocator())\n",
    "    else:\n",
    "        cs = ax.contourf(X,Y,Z)\n",
    "    cb = fig.colorbar(cs)\n",
    "    return fig, ax\n",
    "\n",
    "def animate(objective, background_plotter):\n",
    "    i = 0\n",
    "    overall_best = -np.inf\n",
    "    for pop in genetic_algorithm(Individual, objective, cross, 30, 30):\n",
    "        if i % 2 == 0:\n",
    "            cur_best = max([rosenbrock_objective(ind) for ind in pop])\n",
    "            overall_best = max(overall_best, cur_best)\n",
    "            fig, ax = background_plotter()\n",
    "            ax.set_title(f\"Generation {i}. Current best {cur_best:1.4}. Overall best {overall_best:1.4}\") \n",
    "            vals = pop_to_coords(pop)\n",
    "            ax.scatter(vals[0],vals[1])\n",
    "            display(fig)\n",
    "            clear_output(wait=True)\n",
    "            plt.pause(0.3)\n",
    "        i += 1 \n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335c6f15-4316-46c1-89b3-f5cc123bf8a0",
   "metadata": {},
   "source": [
    "## Rosenbrock\n",
    "\n",
    "This test case uses the objective \n",
    "$$f(x,y) = x^2 + 40(y - x^2) ^2 $$\n",
    "(I have shifted and re-scaled to place it in our domain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da76738-ab90-4d88-99f9-7ff45fe0efb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosenbrock(x, y):\n",
    "    return -((1/2 - x) ** 2 + 40 * (y - x ** 2) ** 2)\n",
    "\n",
    "def rosenbrock_objective(individual):\n",
    "    return rosenbrock(individual.x, individual.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5743742e-0ae6-4162-8e51-97c3905c4a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "rosenbrock_plotter = lambda : background_plot(rosenbrock, logscale=True)\n",
    "animate(rosenbrock_objective, rosenbrock_plotter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3257d6-37d5-47bf-8ac2-6fad9c2095c9",
   "metadata": {},
   "source": [
    "## Rastrigin\n",
    "$$f(x,y) = 2A + x^2 - A\\cos(2\\pi x) + y^2 - A\\cos(2\\pi y)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbd52df-b740-49c9-ac7d-1d7aef5f1145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rastrigin(x, y):\n",
    "    A = 10\n",
    "    scale = 8\n",
    "    x = scale * (x-0.5)\n",
    "    y = scale * (y-0.5)\n",
    "    return -(2*A + x ** 2 - A * np.cos(2 * np.pi * x) + y ** 2 - A * np.cos(2 * np.pi * y))\n",
    "\n",
    "def rastrigin_objective(individual): \n",
    "    return rastrigin(individual.x, individual.y)\n",
    "\n",
    "rastrigin_plotter = lambda : background_plot(rastrigin)\n",
    "animate(rastrigin_objective, rastrigin_plotter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13618a5b-a65f-40de-83c0-ff1865622ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def schaffer(x, y):\n",
    "    scale = 20\n",
    "    x = scale * (x-0.5)\n",
    "    y = scale * (y-0.5)\n",
    "    return -(0.5 + ((np.sin(x ** 2 - y ** 2) ** 2) - 0.5)/((1 + (x ** 2 + y ** 2)/1000) ** 2))\n",
    "\n",
    "def schaffer_objective(individual): \n",
    "    return schaffer(individual.x, individual.y)\n",
    "\n",
    "schaffer_plotter = lambda : background_plot(schaffer)\n",
    "animate(schaffer_objective, schaffer_plotter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d29f4b-735e-4b5b-a7a7-07b6613be18b",
   "metadata": {},
   "source": [
    "## Himmelbau\n",
    "$$f(x,y) =  (x^2 + y - 11)^2 + (x + y^2 -7)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eba9105-91bb-4ff1-a877-f39a336c3f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def himmelbau(x, y):\n",
    "    scale = 10\n",
    "    x = scale * (x-0.5)\n",
    "    y = scale * (y-0.5)\n",
    "    return -((x ** 2 + y - 11) ** 2 + (x + y ** 2 - 7) ** 2)\n",
    "\n",
    "def himmelbau_objective(individual): \n",
    "    return himmelbau(individual.x, individual.y)\n",
    "\n",
    "himmelbau_plotter = lambda : background_plot(himmelbau, logscale = True)\n",
    "animate(himmelbau_objective, himmelbau_plotter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0bc886-1a3c-45a4-82e7-f5c8d15ede3d",
   "metadata": {},
   "source": [
    "# Common Modifications\n",
    "\n",
    "1. __Hill-climbing__: one can add a step (after reproduction/mutation) that performs a local optimization, assuming it is fairly cheap to implement.\n",
    "2. __Elitism__: one can keep the $k$ highest fitness individuals for the next generation. This may cause convergence to local minima, but it may also save valuable information.\n",
    "3. __Tournament Selection__: rather than competing all members of the population together, one can compete random pairs of the population (think two organisms fighting for a mate).\n",
    "4. __Speciation__: keep track of different clusters of solutions in the population. Can penalize mating between similar solutions (incest?).\n",
    "5. __Adaptive Mutation/Crossover Rates__: can increase/decrease mutation crossover rates according to relative fitness.\n",
    "5. __Other Strategies__: can select proportionally to fitness, can keep some parents for the next generation.\n",
    "\n",
    "\n",
    "## Strengths\n",
    "\n",
    "1. Good at avoiding local minima, assuming a good selection of the (many) parameters.\n",
    "2. Multiple objective optimization is relatively natural by selecting according to what level of Pareto front a point is at.\n",
    "3. Applies well to discrete problems with large design spaces or odd representations of the solution space (e.g. decision trees, graphs, timetables).\n",
    "4. Can be robust to changes of objective/constraint if a diverse population is maintained.\n",
    "\n",
    "\n",
    "## Weaknesses\n",
    "\n",
    "1. Bad at optimizing locally. Usually the last few \"mutations\" are hard to find, and other algorithms will perform a better local optimization.\n",
    "2. May have slow rates of convergence/be computationally expensive (requiring many objective evaluations). An alternative for situations with expensive objective evaluations is Bayesian optimiziation!\n",
    "3. Problems with few possible fitness values. One is basically just relying on mutations.\n",
    "\n",
    "\n",
    "## Principles\n",
    "\n",
    "1. Diversity gives robustness to changes in objective/constraints\n",
    "2. Maintaining as large of a feasible space as possible. Rather than implementing constraints, implement a penalty.\n",
    "3. Exploration-Exploitation\n",
    "\n",
    "\n",
    "# Theoretical results\n",
    "\n",
    "Some. Usually convergence guarantees for genetic algorithms require problems that have a lot of structure with which one can work. A common technique is to analyze the Markov chain associated to an evolution iteration.\n",
    "\n",
    "\n",
    "# Standard Applications\n",
    "\n",
    "1. Scheduling\n",
    "2. Neural Architecture Search\n",
    "3. Symbolic Regression\n",
    "\n",
    "\n",
    "# Software\n",
    "\n",
    "I am familiar with [PyMOO](https://www.pymoo.org), a fun package that implements a lot of evolutionary algorithms (genetic algorithm, particle-swarm optimization, multi-objective algorithms, etc.)\n",
    "\n",
    "\n",
    "# Other classes of bio-inspired algorithms\n",
    "\n",
    "1. Particle swarm optimization\n",
    "2. Cuckoo search\n",
    "3. Ant colony optimization\n",
    "4. Bee colony optimization\n",
    "5. Firefly algorithm\n",
    "6. Harmony search\n",
    "7. Memetic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4290b82b-4d35-4ae6-b711-4efcf139ae3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
